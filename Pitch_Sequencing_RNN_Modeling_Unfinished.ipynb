{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNE2G07KZ0Bm",
        "outputId": "63c28b77-b2db-4468-a516-76036bc51b5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "On56G4XEZiAc"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Loading in Data\n",
        "sale = pd.read_csv('/content/sale_modeling.csv')\n",
        "skubal = pd.read_csv('/content/skubal_modeling.csv')"
      ],
      "metadata": {
        "id": "R2KYKUFKZ4rD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Now that all the necessary steps before modeling are done, I can start actually modeling. To do so, I need to hyperparameter tune, evaluate, and select the best models. I also will be doing this separately for each pitcher. At the end of this, while I don't think I will get perfect results, I would like to see if there is a difference in prediction accuracy with these pitchers.\n",
        "\n",
        "Note: In my experience with RNNs, I have never used PyTorch. This project is going to help me learn PyTorch along with learn actually about what the models produce."
      ],
      "metadata": {
        "id": "QI78w_bnaFv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chris Sale\n"
      ],
      "metadata": {
        "id": "mXl_c1ERbFt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First thing's first, I need to split the data into training and testing. I will use 80% of the sequences to train and 20% of the data to test."
      ],
      "metadata": {
        "id": "uw8FGKu5i_qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_sale(data, features, sequence_length=3): ## Need different functions for Sale and Skubal because they have different arsenals\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    for seq_id, group in data.groupby('seq_id'):\n",
        "        pitch_features = group[features].values\n",
        "        pitch_types = group[['pitch_type_CH', 'pitch_type_FF', 'pitch_type_SI', 'pitch_type_SL']].values\n",
        "\n",
        "        if len(pitch_features) >= sequence_length + 1:\n",
        "            for i in range(len(pitch_features) - sequence_length):\n",
        "                sequences.append(pitch_features[i:i + sequence_length])\n",
        "                targets.append(pitch_types[i + sequence_length])\n",
        "\n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "\n",
        "## Explanatory pitch features\n",
        "features = ['release_speed', 'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
        "            'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'plate_x', 'plate_z',\n",
        "            'sz_top', 'sz_bot', 'balls', 'strikes', 'outs_when_up', 'inning',\n",
        "            'inning_topbot_Bot', 'inning_topbot_Top', 'stand_L', 'stand_R', 'p_throws_L']\n",
        "\n",
        "X, y = create_sequences_sale(sale, features)\n",
        "\n",
        "def train_test_split_sequences(data, features, test_size=0.2):\n",
        "\n",
        "    unique_seq_ids = data['seq_id'].unique()\n",
        "    train_ids, test_ids = train_test_split(unique_seq_ids, test_size=test_size, random_state=42)\n",
        "\n",
        "    train_df = data[data['seq_id'].isin(train_ids)]\n",
        "    test_df = data[data['seq_id'].isin(test_ids)]\n",
        "\n",
        "    X_train, y_train = create_sequences_sale(train_df, features)\n",
        "    X_test, y_test = create_sequences_sale(test_df, features)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "## Creating actual splits\n",
        "X_train_sale, y_train_sale, X_test_sale, y_test_sale = train_test_split_sequences(sale, features)"
      ],
      "metadata": {
        "id": "cY_qrF1an5eo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning using Optuna\n",
        "\n",
        "This is my first time using Optuna in cahoots with Pytorch RNN building, so I am still learning.\n",
        "\n",
        "For my model, I am choosing to use Gated Recurrent Units (GRU) instead of LSTM because the sequences are short and simple (3 timesteps). LSTMs work better when the sequences are longer. Also, I don't have the computational power to run a good enough LSTM."
      ],
      "metadata": {
        "id": "a3czy3SojANr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE = 64\n",
        "EPOCHS = 10\n",
        "DIR = os.getcwd()\n",
        "\n",
        "## Creating the GRU -- Need dropouts because with such small data and the fact that there aren't many options for output, overfitting is a risk\n",
        "def create_gru_model(input_size, hidden_size, num_layers, output_size, dropout_rate):\n",
        "    gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    dropout = nn.Dropout(dropout_rate)\n",
        "    linear = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        gru,\n",
        "        Lambda(lambda x: x[0]), ## Extracting output layer\n",
        "        dropout,\n",
        "        linear,\n",
        "        nn.Dropout(dropout_rate)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "## Lambda layer for extracting the output\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "## For Hyperparameter Tuning\n",
        "def objective(trial):\n",
        "\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 128)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-5, 1e-3, log=True)\n",
        "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 3])\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "\n",
        "    ## Create GRU model using above function\n",
        "    model = create_gru_model(input_size=21, hidden_size=hidden_size, num_layers=num_layers, output_size=4, dropout_rate= dropout)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    ## Converting data to PyTorch tensors\n",
        "    X_train_tensor = torch.tensor(X_train_sale, dtype=torch.float32)\n",
        "\n",
        "    # Convert one-hot encoded target to class indices\n",
        "    y_train_sale_classes = np.argmax(y_train_sale, axis=1)\n",
        "    y_train_tensor = torch.tensor(y_train_sale_classes, dtype=torch.long)\n",
        "\n",
        "    # Training over epochs\n",
        "    for epoch in range(EPOCHS):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train_tensor)\n",
        "        outputs = outputs[:, -1, :]\n",
        "        loss = criterion(outputs, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_train_tensor)\n",
        "        outputs = outputs[:, -1, :]\n",
        "        loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct = (predicted == y_train_tensor).sum().item()\n",
        "        total = y_train_tensor.size(0)\n",
        "        accuracy = correct / total\n",
        "\n",
        "    return loss.item(), accuracy  # Return both loss and accuracy\n",
        "\n",
        "# Create and run the Optuna study\n",
        "study = optuna.create_study(directions=[\"minimize\", \"maximize\"]) ## For loss and accuracy\n",
        "study.optimize(objective, n_trials=80, n_jobs=1)\n",
        "\n",
        "\n",
        "# Get the best trial and hyperparameters\n",
        "best_trials = study.best_trials\n",
        "\n",
        "# Print the best trials\n",
        "for trial in best_trials:\n",
        "    print(\"Trial params:\", trial.params)\n",
        "    print(\"Trial Accuracy:\", trial.values[1])\n",
        "    print(\"Trial Loss:\", trial.values[0])\n",
        "\n",
        "study_filename = \"optuna_study_sale.pkl\"\n",
        "joblib.dump(study, study_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IzQpFC9i_4F",
        "outputId": "674ae225-6b3f-4fec-b0b9-f02b99c4b758",
        "collapsed": true
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-25 20:09:56,148] A new study created in memory with name: no-name-54c2d908-8e25-4556-9f5d-3d72e0ca30db\n",
            "[I 2025-03-25 20:09:56,350] Trial 0 finished with values: [1.350733995437622, 0.37116564417177916] and parameters: {'hidden_size': 79, 'learning_rate': 5.907158038440355e-05, 'num_layers': 3, 'dropout': 0.20217129253951638}.\n",
            "[I 2025-03-25 20:09:56,423] Trial 1 finished with values: [1.2792413234710693, 0.48466257668711654] and parameters: {'hidden_size': 83, 'learning_rate': 0.0009102727954844167, 'num_layers': 1, 'dropout': 0.19758609048658846}.\n",
            "[I 2025-03-25 20:09:56,711] Trial 2 finished with values: [1.2947088479995728, 0.44171779141104295] and parameters: {'hidden_size': 101, 'learning_rate': 0.0004831071558914533, 'num_layers': 3, 'dropout': 0.27309959686721413}.\n",
            "[I 2025-03-25 20:09:57,061] Trial 3 finished with values: [1.3581626415252686, 0.30368098159509205] and parameters: {'hidden_size': 123, 'learning_rate': 9.989464381968638e-05, 'num_layers': 3, 'dropout': 0.3185413707307828}.\n",
            "[I 2025-03-25 20:09:57,227] Trial 4 finished with values: [1.2928811311721802, 0.4539877300613497] and parameters: {'hidden_size': 61, 'learning_rate': 0.0007942770390421613, 'num_layers': 3, 'dropout': 0.309338541665726}.\n",
            "[I 2025-03-25 20:09:57,401] Trial 5 finished with values: [1.3358443975448608, 0.3987730061349693] and parameters: {'hidden_size': 80, 'learning_rate': 0.00016962186933068576, 'num_layers': 3, 'dropout': 0.14769513608130264}.\n",
            "[I 2025-03-25 20:09:57,446] Trial 6 finished with values: [1.345978856086731, 0.30368098159509205] and parameters: {'hidden_size': 44, 'learning_rate': 0.0004088377758262437, 'num_layers': 1, 'dropout': 0.15925000598680478}.\n",
            "[I 2025-03-25 20:09:57,529] Trial 7 finished with values: [1.4478360414505005, 0.15030674846625766] and parameters: {'hidden_size': 43, 'learning_rate': 6.216934179874887e-05, 'num_layers': 2, 'dropout': 0.43222312283811015}.\n",
            "[I 2025-03-25 20:09:57,639] Trial 8 finished with values: [1.4031413793563843, 0.1687116564417178] and parameters: {'hidden_size': 123, 'learning_rate': 0.0002721682985580448, 'num_layers': 1, 'dropout': 0.28451957497614233}.\n",
            "[I 2025-03-25 20:09:57,721] Trial 9 finished with values: [1.380328893661499, 0.2085889570552147] and parameters: {'hidden_size': 37, 'learning_rate': 6.699574888076485e-05, 'num_layers': 2, 'dropout': 0.43143069358552577}.\n",
            "[I 2025-03-25 20:09:57,821] Trial 10 finished with values: [1.3054286241531372, 0.4171779141104294] and parameters: {'hidden_size': 48, 'learning_rate': 0.0008409010025634499, 'num_layers': 3, 'dropout': 0.21555292245983165}.\n",
            "[I 2025-03-25 20:09:57,872] Trial 11 finished with values: [1.3728636503219604, 0.29141104294478526] and parameters: {'hidden_size': 33, 'learning_rate': 0.0007171924736615213, 'num_layers': 2, 'dropout': 0.1306115202539171}.\n",
            "[I 2025-03-25 20:09:58,044] Trial 12 finished with values: [1.3301690816879272, 0.4325153374233129] and parameters: {'hidden_size': 76, 'learning_rate': 0.0004311402013432208, 'num_layers': 3, 'dropout': 0.4119227032842442}.\n",
            "[I 2025-03-25 20:09:58,171] Trial 13 finished with values: [1.366761326789856, 0.3343558282208589] and parameters: {'hidden_size': 88, 'learning_rate': 0.00012728083378054457, 'num_layers': 2, 'dropout': 0.46446523941149065}.\n",
            "[I 2025-03-25 20:09:58,248] Trial 14 finished with values: [1.396684169769287, 0.2607361963190184] and parameters: {'hidden_size': 106, 'learning_rate': 0.00010215057356809039, 'num_layers': 1, 'dropout': 0.3976182139290537}.\n",
            "[I 2025-03-25 20:09:58,463] Trial 15 finished with values: [1.3576345443725586, 0.3619631901840491] and parameters: {'hidden_size': 96, 'learning_rate': 0.00022325053265010445, 'num_layers': 3, 'dropout': 0.43133601431322677}.\n",
            "[I 2025-03-25 20:09:58,589] Trial 16 finished with values: [1.3497132062911987, 0.2822085889570552] and parameters: {'hidden_size': 80, 'learning_rate': 6.303793388528524e-05, 'num_layers': 2, 'dropout': 0.2627913986857283}.\n",
            "[I 2025-03-25 20:09:58,838] Trial 17 finished with values: [1.3744920492172241, 0.3312883435582822] and parameters: {'hidden_size': 94, 'learning_rate': 0.00020962814592509894, 'num_layers': 3, 'dropout': 0.15988783756895086}.\n",
            "[I 2025-03-25 20:09:58,943] Trial 18 finished with values: [1.3838131427764893, 0.27607361963190186] and parameters: {'hidden_size': 126, 'learning_rate': 0.00011428918387119484, 'num_layers': 1, 'dropout': 0.32168514734827824}.\n",
            "[I 2025-03-25 20:09:59,118] Trial 19 finished with values: [1.3640621900558472, 0.36809815950920244] and parameters: {'hidden_size': 108, 'learning_rate': 0.0002257401400822547, 'num_layers': 2, 'dropout': 0.27239521166440467}.\n",
            "[I 2025-03-25 20:09:59,411] Trial 20 finished with values: [1.306557536125183, 0.4447852760736196] and parameters: {'hidden_size': 110, 'learning_rate': 0.00027160383219551756, 'num_layers': 3, 'dropout': 0.25243856059031905}.\n",
            "[I 2025-03-25 20:09:59,714] Trial 21 finished with values: [1.3560786247253418, 0.42024539877300615] and parameters: {'hidden_size': 113, 'learning_rate': 0.00015483815344293915, 'num_layers': 3, 'dropout': 0.26108908473928716}.\n",
            "[I 2025-03-25 20:09:59,759] Trial 22 finished with values: [1.2963348627090454, 0.4171779141104294] and parameters: {'hidden_size': 45, 'learning_rate': 0.0007567073829137522, 'num_layers': 1, 'dropout': 0.1515200038915046}.\n",
            "[I 2025-03-25 20:09:59,977] Trial 23 finished with values: [1.340586543083191, 0.40797546012269936] and parameters: {'hidden_size': 124, 'learning_rate': 0.0001990077794440067, 'num_layers': 2, 'dropout': 0.36823548326342326}.\n",
            "[I 2025-03-25 20:10:00,119] Trial 24 finished with values: [1.3649324178695679, 0.34662576687116564] and parameters: {'hidden_size': 86, 'learning_rate': 6.517269052969379e-05, 'num_layers': 2, 'dropout': 0.16822162841669153}.\n",
            "[I 2025-03-25 20:10:00,208] Trial 25 finished with values: [1.394574761390686, 0.26380368098159507] and parameters: {'hidden_size': 34, 'learning_rate': 0.00016305929079467205, 'num_layers': 3, 'dropout': 0.4922957615474627}.\n",
            "[I 2025-03-25 20:10:00,345] Trial 26 finished with values: [1.3440070152282715, 0.401840490797546] and parameters: {'hidden_size': 78, 'learning_rate': 0.0003432664598351407, 'num_layers': 2, 'dropout': 0.34852254929365667}.\n",
            "[I 2025-03-25 20:10:00,384] Trial 27 finished with values: [1.479681134223938, 0.19325153374233128] and parameters: {'hidden_size': 38, 'learning_rate': 0.00023136692578267558, 'num_layers': 1, 'dropout': 0.3893130308287561}.\n",
            "[I 2025-03-25 20:10:00,607] Trial 28 finished with values: [1.3552285432815552, 0.48466257668711654] and parameters: {'hidden_size': 119, 'learning_rate': 0.00029236126121637057, 'num_layers': 2, 'dropout': 0.11064369645624104}.\n",
            "[I 2025-03-25 20:10:00,678] Trial 29 finished with values: [1.3972316980361938, 0.26380368098159507] and parameters: {'hidden_size': 85, 'learning_rate': 6.330528951944292e-05, 'num_layers': 1, 'dropout': 0.3508711315937344}.\n",
            "[I 2025-03-25 20:10:00,744] Trial 30 finished with values: [1.3819719552993774, 0.24846625766871167] and parameters: {'hidden_size': 60, 'learning_rate': 0.00013228321971759554, 'num_layers': 1, 'dropout': 0.14192195878316283}.\n",
            "[I 2025-03-25 20:10:00,911] Trial 31 finished with values: [1.3674043416976929, 0.3773006134969325] and parameters: {'hidden_size': 80, 'learning_rate': 6.835420929571733e-05, 'num_layers': 3, 'dropout': 0.22974979103055718}.\n",
            "[I 2025-03-25 20:10:01,055] Trial 32 finished with values: [1.3804153203964233, 0.29141104294478526] and parameters: {'hidden_size': 55, 'learning_rate': 0.00018072596452054285, 'num_layers': 3, 'dropout': 0.355662848469922}.\n",
            "[I 2025-03-25 20:10:01,176] Trial 33 finished with values: [1.3653942346572876, 0.30368098159509205] and parameters: {'hidden_size': 71, 'learning_rate': 0.0002478409544913777, 'num_layers': 2, 'dropout': 0.4655727645728217}.\n",
            "[I 2025-03-25 20:10:01,462] Trial 34 finished with values: [1.3862136602401733, 0.25153374233128833] and parameters: {'hidden_size': 107, 'learning_rate': 0.00012463931546704985, 'num_layers': 3, 'dropout': 0.43398628370596204}.\n",
            "[I 2025-03-25 20:10:01,505] Trial 35 finished with values: [1.3949803113937378, 0.22392638036809817] and parameters: {'hidden_size': 42, 'learning_rate': 7.591921446704733e-05, 'num_layers': 1, 'dropout': 0.28444888877766594}.\n",
            "[I 2025-03-25 20:10:01,627] Trial 36 finished with values: [1.3041844367980957, 0.36503067484662577] and parameters: {'hidden_size': 70, 'learning_rate': 0.0008505924493379839, 'num_layers': 2, 'dropout': 0.46784423748389214}.\n",
            "[I 2025-03-25 20:10:01,747] Trial 37 finished with values: [1.365994930267334, 0.27300613496932513] and parameters: {'hidden_size': 127, 'learning_rate': 0.00010127567000505152, 'num_layers': 1, 'dropout': 0.13733611554943592}.\n",
            "[I 2025-03-25 20:10:01,957] Trial 38 finished with values: [1.376678228378296, 0.3128834355828221] and parameters: {'hidden_size': 96, 'learning_rate': 8.878260027668817e-05, 'num_layers': 3, 'dropout': 0.3847455570084011}.\n",
            "[I 2025-03-25 20:10:02,065] Trial 39 finished with values: [1.3694357872009277, 0.3159509202453988] and parameters: {'hidden_size': 63, 'learning_rate': 0.0003398739050528781, 'num_layers': 2, 'dropout': 0.31992798202132056}.\n",
            "[I 2025-03-25 20:10:02,354] Trial 40 finished with values: [1.3581892251968384, 0.4539877300613497] and parameters: {'hidden_size': 116, 'learning_rate': 0.00013450089500356772, 'num_layers': 3, 'dropout': 0.19384966204494686}.\n",
            "[I 2025-03-25 20:10:02,497] Trial 41 finished with values: [1.430956244468689, 0.17484662576687116] and parameters: {'hidden_size': 85, 'learning_rate': 7.594012383931983e-05, 'num_layers': 2, 'dropout': 0.4777667951719794}.\n",
            "[I 2025-03-25 20:10:02,664] Trial 42 finished with values: [1.344976544380188, 0.401840490797546] and parameters: {'hidden_size': 112, 'learning_rate': 0.00024494956982896917, 'num_layers': 2, 'dropout': 0.21281214339589793}.\n",
            "[I 2025-03-25 20:10:02,773] Trial 43 finished with values: [1.341623067855835, 0.3006134969325153] and parameters: {'hidden_size': 65, 'learning_rate': 0.00021621212244184927, 'num_layers': 2, 'dropout': 0.2408858475427152}.\n",
            "[I 2025-03-25 20:10:02,896] Trial 44 finished with values: [1.2896411418914795, 0.46319018404907975] and parameters: {'hidden_size': 64, 'learning_rate': 0.00042478312403018025, 'num_layers': 3, 'dropout': 0.16577774433066883}.\n",
            "[I 2025-03-25 20:10:03,031] Trial 45 finished with values: [1.3218549489974976, 0.43558282208588955] and parameters: {'hidden_size': 53, 'learning_rate': 0.00048239853924257056, 'num_layers': 3, 'dropout': 0.20989102896299344}.\n",
            "[I 2025-03-25 20:10:03,103] Trial 46 finished with values: [1.2727833986282349, 0.4447852760736196] and parameters: {'hidden_size': 96, 'learning_rate': 0.000748891525135518, 'num_layers': 1, 'dropout': 0.3425772181690237}.\n",
            "[I 2025-03-25 20:10:03,273] Trial 47 finished with values: [1.3501240015029907, 0.3803680981595092] and parameters: {'hidden_size': 103, 'learning_rate': 0.00014448074921185518, 'num_layers': 2, 'dropout': 0.26403893483523283}.\n",
            "[I 2025-03-25 20:10:03,552] Trial 48 finished with values: [1.2227370738983154, 0.4754601226993865] and parameters: {'hidden_size': 120, 'learning_rate': 0.0007840036283701464, 'num_layers': 3, 'dropout': 0.13360350428840773}.\n",
            "[I 2025-03-25 20:10:03,615] Trial 49 finished with values: [1.3637171983718872, 0.3588957055214724] and parameters: {'hidden_size': 35, 'learning_rate': 7.273299717076955e-05, 'num_layers': 2, 'dropout': 0.1820285326961674}.\n",
            "[I 2025-03-25 20:10:03,676] Trial 50 finished with values: [1.295709490776062, 0.46932515337423314] and parameters: {'hidden_size': 57, 'learning_rate': 0.0007567073829137522, 'num_layers': 1, 'dropout': 0.1515200038915046}.\n",
            "[I 2025-03-25 20:10:03,788] Trial 51 finished with values: [1.3509070873260498, 0.401840490797546] and parameters: {'hidden_size': 48, 'learning_rate': 6.098391653339911e-05, 'num_layers': 3, 'dropout': 0.21555292245983165}.\n",
            "[I 2025-03-25 20:10:03,879] Trial 52 finished with values: [1.3857232332229614, 0.2607361963190184] and parameters: {'hidden_size': 113, 'learning_rate': 0.00027160383219551756, 'num_layers': 1, 'dropout': 0.26108908473928716}.\n",
            "[I 2025-03-25 20:10:03,936] Trial 53 finished with values: [1.39391028881073, 0.2392638036809816] and parameters: {'hidden_size': 70, 'learning_rate': 0.00020962814592509894, 'num_layers': 1, 'dropout': 0.48951108260583764}.\n",
            "[I 2025-03-25 20:10:04,097] Trial 54 finished with values: [1.3025257587432861, 0.4662576687116564] and parameters: {'hidden_size': 93, 'learning_rate': 0.0005878310606102539, 'num_layers': 2, 'dropout': 0.26403893483523283}.\n",
            "[I 2025-03-25 20:10:04,165] Trial 55 finished with values: [1.3912590742111206, 0.26380368098159507] and parameters: {'hidden_size': 83, 'learning_rate': 6.303793388528524e-05, 'num_layers': 1, 'dropout': 0.29691219409890623}.\n",
            "[I 2025-03-25 20:10:04,296] Trial 56 finished with values: [1.3613134622573853, 0.31901840490797545] and parameters: {'hidden_size': 64, 'learning_rate': 0.00027160383219551756, 'num_layers': 3, 'dropout': 0.33962331352990016}.\n",
            "[I 2025-03-25 20:10:04,510] Trial 57 finished with values: [1.3441736698150635, 0.41411042944785276] and parameters: {'hidden_size': 96, 'learning_rate': 8.878260027668817e-05, 'num_layers': 3, 'dropout': 0.16822162841669153}.\n",
            "[I 2025-03-25 20:10:04,645] Trial 58 finished with values: [1.3418045043945312, 0.40797546012269936] and parameters: {'hidden_size': 78, 'learning_rate': 0.0003432664598351407, 'num_layers': 2, 'dropout': 0.34852254929365667}.\n",
            "[I 2025-03-25 20:10:04,862] Trial 59 finished with values: [1.2707329988479614, 0.43558282208588955] and parameters: {'hidden_size': 111, 'learning_rate': 0.0006690849303619035, 'num_layers': 2, 'dropout': 0.43133601431322677}.\n",
            "[I 2025-03-25 20:10:05,056] Trial 60 finished with values: [1.2200591564178467, 0.5061349693251533] and parameters: {'hidden_size': 110, 'learning_rate': 0.0008505924493379839, 'num_layers': 2, 'dropout': 0.11898358190583852}.\n",
            "[I 2025-03-25 20:10:05,102] Trial 61 finished with values: [1.364633321762085, 0.31901840490797545] and parameters: {'hidden_size': 45, 'learning_rate': 0.0007567073829137522, 'num_layers': 1, 'dropout': 0.1515200038915046}.\n",
            "[I 2025-03-25 20:10:05,194] Trial 62 finished with values: [1.370531678199768, 0.2883435582822086] and parameters: {'hidden_size': 110, 'learning_rate': 0.00027160383219551756, 'num_layers': 1, 'dropout': 0.25243856059031905}.\n",
            "[I 2025-03-25 20:10:05,323] Trial 63 finished with values: [1.334957480430603, 0.3282208588957055] and parameters: {'hidden_size': 53, 'learning_rate': 0.0004311402013432208, 'num_layers': 3, 'dropout': 0.21281214339589793}.\n",
            "[I 2025-03-25 20:10:05,455] Trial 64 finished with values: [1.386417269706726, 0.32515337423312884] and parameters: {'hidden_size': 55, 'learning_rate': 0.00018072596452054285, 'num_layers': 3, 'dropout': 0.13360350428840773}.\n",
            "[I 2025-03-25 20:10:05,801] Trial 65 finished with values: [1.3082722425460815, 0.44785276073619634] and parameters: {'hidden_size': 123, 'learning_rate': 0.00027160383219551756, 'num_layers': 3, 'dropout': 0.30191010816390496}.\n",
            "[I 2025-03-25 20:10:05,963] Trial 66 finished with values: [1.2727231979370117, 0.46319018404907975] and parameters: {'hidden_size': 80, 'learning_rate': 0.0007942770390421613, 'num_layers': 3, 'dropout': 0.22974979103055718}.\n",
            "[I 2025-03-25 20:10:06,060] Trial 67 finished with values: [1.3321714401245117, 0.3895705521472393] and parameters: {'hidden_size': 103, 'learning_rate': 0.00014448074921185518, 'num_layers': 1, 'dropout': 0.27239521166440467}.\n",
            "[I 2025-03-25 20:10:06,231] Trial 68 finished with values: [1.3415597677230835, 0.43558282208588955] and parameters: {'hidden_size': 54, 'learning_rate': 0.00042478312403018025, 'num_layers': 3, 'dropout': 0.16577774433066883}.\n",
            "[I 2025-03-25 20:10:06,451] Trial 69 finished with values: [1.4055274724960327, 0.2392638036809816] and parameters: {'hidden_size': 71, 'learning_rate': 0.0002478409544913777, 'num_layers': 3, 'dropout': 0.4655727645728217}.\n",
            "[I 2025-03-25 20:10:06,534] Trial 70 finished with values: [1.317725658416748, 0.3834355828220859] and parameters: {'hidden_size': 40, 'learning_rate': 0.00012204610413258628, 'num_layers': 2, 'dropout': 0.4119227032842442}.\n",
            "[I 2025-03-25 20:10:06,845] Trial 71 finished with values: [1.3774027824401855, 0.34662576687116564] and parameters: {'hidden_size': 97, 'learning_rate': 0.00029236126121637057, 'num_layers': 3, 'dropout': 0.11064369645624104}.\n",
            "[I 2025-03-25 20:10:07,113] Trial 72 finished with values: [1.3616150617599487, 0.34355828220858897] and parameters: {'hidden_size': 96, 'learning_rate': 8.878260027668817e-05, 'num_layers': 3, 'dropout': 0.3847455570084011}.\n",
            "[I 2025-03-25 20:10:07,385] Trial 73 finished with values: [1.3664414882659912, 0.36503067484662577] and parameters: {'hidden_size': 79, 'learning_rate': 0.00024494956982896917, 'num_layers': 3, 'dropout': 0.21281214339589793}.\n",
            "[I 2025-03-25 20:10:07,438] Trial 74 finished with values: [1.3894708156585693, 0.2361963190184049] and parameters: {'hidden_size': 64, 'learning_rate': 0.0002257401400822547, 'num_layers': 1, 'dropout': 0.16577774433066883}.\n",
            "[I 2025-03-25 20:10:07,523] Trial 75 finished with values: [1.2578186988830566, 0.4662576687116564] and parameters: {'hidden_size': 112, 'learning_rate': 0.0009102727954844167, 'num_layers': 1, 'dropout': 0.21281214339589793}.\n",
            "[I 2025-03-25 20:10:07,588] Trial 76 finished with values: [1.3961007595062256, 0.3343558282208589] and parameters: {'hidden_size': 35, 'learning_rate': 7.273299717076955e-05, 'num_layers': 2, 'dropout': 0.1820285326961674}.\n",
            "[I 2025-03-25 20:10:07,908] Trial 77 finished with values: [1.264006495475769, 0.4570552147239264] and parameters: {'hidden_size': 110, 'learning_rate': 0.000748891525135518, 'num_layers': 3, 'dropout': 0.25243856059031905}.\n",
            "[I 2025-03-25 20:10:08,055] Trial 78 finished with values: [1.3332396745681763, 0.4754601226993865] and parameters: {'hidden_size': 96, 'learning_rate': 0.0003432664598351407, 'num_layers': 2, 'dropout': 0.20989102896299344}.\n",
            "[I 2025-03-25 20:10:08,262] Trial 79 finished with values: [1.3442562818527222, 0.3895705521472393] and parameters: {'hidden_size': 85, 'learning_rate': 0.00013450089500356772, 'num_layers': 3, 'dropout': 0.19384966204494686}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial params: {'hidden_size': 110, 'learning_rate': 0.0008505924493379839, 'num_layers': 2, 'dropout': 0.11898358190583852}\n",
            "Trial Accuracy: 0.5061349693251533\n",
            "Trial Loss: 1.2200591564178467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optuna_study_sale.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on Optuna's hyperparameter tuning here, we have a few best trials. I am going to use some of Optuna's visualization techniques to compare trials."
      ],
      "metadata": {
        "id": "Oed8SntAs-Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study_sale = joblib.load(\"optuna_study_sale.pkl\")\n",
        "print(\"\\033[1m\\033[94mChris Sale Hyperparameter Tuning with Optuna, all trials.\\033[0m\")\n",
        "optuna.visualization.plot_pareto_front(study_sale)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "NRJg6iB8tQm-",
        "outputId": "fc7c149d-1d48-4508-c383-2da368ab9d7b"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94mChris Sale Hyperparameter Tuning with Optuna, all trials.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"12764f2c-e342-43c2-ad44-768ce0e75bc3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"12764f2c-e342-43c2-ad44-768ce0e75bc3\")) {                    Plotly.newPlot(                        \"12764f2c-e342-43c2-ad44-768ce0e75bc3\",                        [{\"hovertemplate\":\"%{text}\\u003cextra\\u003eTrial\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79],\"colorbar\":{\"title\":{\"text\":\"Trial\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5}},\"mode\":\"markers\",\"showlegend\":false,\"text\":[\"{\\u003cbr\\u003e  \\\"number\\\": 0,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.350733995437622,\\u003cbr\\u003e    0.37116564417177916\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 79,\\u003cbr\\u003e    \\\"learning_rate\\\": 5.907158038440355e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.20217129253951638\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 1,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2792413234710693,\\u003cbr\\u003e    0.48466257668711654\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 83,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0009102727954844167,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.19758609048658846\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 2,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2947088479995728,\\u003cbr\\u003e    0.44171779141104295\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 101,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0004831071558914533,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.27309959686721413\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 3,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3581626415252686,\\u003cbr\\u003e    0.30368098159509205\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 123,\\u003cbr\\u003e    \\\"learning_rate\\\": 9.989464381968638e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.3185413707307828\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 4,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2928811311721802,\\u003cbr\\u003e    0.4539877300613497\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 61,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0007942770390421613,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.309338541665726\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 5,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3358443975448608,\\u003cbr\\u003e    0.3987730061349693\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 80,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00016962186933068576,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.14769513608130264\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 6,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.345978856086731,\\u003cbr\\u003e    0.30368098159509205\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 44,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0004088377758262437,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.15925000598680478\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 7,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.4478360414505005,\\u003cbr\\u003e    0.15030674846625766\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 43,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.216934179874887e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.43222312283811015\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 8,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.4031413793563843,\\u003cbr\\u003e    0.1687116564417178\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 123,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0002721682985580448,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.28451957497614233\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 9,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.380328893661499,\\u003cbr\\u003e    0.2085889570552147\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 37,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.699574888076485e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.43143069358552577\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 10,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3054286241531372,\\u003cbr\\u003e    0.4171779141104294\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 48,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0008409010025634499,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.21555292245983165\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 11,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3728636503219604,\\u003cbr\\u003e    0.29141104294478526\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 33,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0007171924736615213,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.1306115202539171\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 12,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3301690816879272,\\u003cbr\\u003e    0.4325153374233129\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 76,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0004311402013432208,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.4119227032842442\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 13,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.366761326789856,\\u003cbr\\u003e    0.3343558282208589\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 88,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00012728083378054457,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.46446523941149065\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 14,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.396684169769287,\\u003cbr\\u003e    0.2607361963190184\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 106,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00010215057356809039,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.3976182139290537\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 15,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3576345443725586,\\u003cbr\\u003e    0.3619631901840491\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 96,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00022325053265010445,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.43133601431322677\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 16,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3497132062911987,\\u003cbr\\u003e    0.2822085889570552\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 80,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.303793388528524e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.2627913986857283\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 17,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3744920492172241,\\u003cbr\\u003e    0.3312883435582822\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 94,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00020962814592509894,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.15988783756895086\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 18,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3838131427764893,\\u003cbr\\u003e    0.27607361963190186\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 126,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00011428918387119484,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.32168514734827824\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 19,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3640621900558472,\\u003cbr\\u003e    0.36809815950920244\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 108,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0002257401400822547,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.27239521166440467\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 20,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.306557536125183,\\u003cbr\\u003e    0.4447852760736196\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 110,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00027160383219551756,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.25243856059031905\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 21,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3560786247253418,\\u003cbr\\u003e    0.42024539877300615\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 113,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00015483815344293915,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.26108908473928716\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 22,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2963348627090454,\\u003cbr\\u003e    0.4171779141104294\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 45,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0007567073829137522,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.1515200038915046\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 23,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.340586543083191,\\u003cbr\\u003e    0.40797546012269936\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 124,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0001990077794440067,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.36823548326342326\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 24,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3649324178695679,\\u003cbr\\u003e    0.34662576687116564\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 86,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.517269052969379e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.16822162841669153\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 25,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.394574761390686,\\u003cbr\\u003e    0.26380368098159507\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 34,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00016305929079467205,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.4922957615474627\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 26,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3440070152282715,\\u003cbr\\u003e    0.401840490797546\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 78,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0003432664598351407,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.34852254929365667\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 27,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.479681134223938,\\u003cbr\\u003e    0.19325153374233128\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 38,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00023136692578267558,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.3893130308287561\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 28,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3552285432815552,\\u003cbr\\u003e    0.48466257668711654\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 119,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00029236126121637057,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.11064369645624104\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 29,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3972316980361938,\\u003cbr\\u003e    0.26380368098159507\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 85,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.330528951944292e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.3508711315937344\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 30,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3819719552993774,\\u003cbr\\u003e    0.24846625766871167\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 60,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00013228321971759554,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.14192195878316283\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 31,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3674043416976929,\\u003cbr\\u003e    0.3773006134969325\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 80,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.835420929571733e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.22974979103055718\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 32,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3804153203964233,\\u003cbr\\u003e    0.29141104294478526\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 55,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00018072596452054285,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.355662848469922\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 33,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3653942346572876,\\u003cbr\\u003e    0.30368098159509205\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 71,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0002478409544913777,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.4655727645728217\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 34,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3862136602401733,\\u003cbr\\u003e    0.25153374233128833\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 107,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00012463931546704985,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.43398628370596204\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 35,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3949803113937378,\\u003cbr\\u003e    0.22392638036809817\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 42,\\u003cbr\\u003e    \\\"learning_rate\\\": 7.591921446704733e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.28444888877766594\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 36,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3041844367980957,\\u003cbr\\u003e    0.36503067484662577\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 70,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0008505924493379839,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.46784423748389214\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 37,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.365994930267334,\\u003cbr\\u003e    0.27300613496932513\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 127,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00010127567000505152,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.13733611554943592\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 38,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.376678228378296,\\u003cbr\\u003e    0.3128834355828221\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 96,\\u003cbr\\u003e    \\\"learning_rate\\\": 8.878260027668817e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.3847455570084011\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 39,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3694357872009277,\\u003cbr\\u003e    0.3159509202453988\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 63,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0003398739050528781,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.31992798202132056\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 40,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3581892251968384,\\u003cbr\\u003e    0.4539877300613497\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 116,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00013450089500356772,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.19384966204494686\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 41,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.430956244468689,\\u003cbr\\u003e    0.17484662576687116\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 85,\\u003cbr\\u003e    \\\"learning_rate\\\": 7.594012383931983e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.4777667951719794\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 42,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.344976544380188,\\u003cbr\\u003e    0.401840490797546\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 112,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00024494956982896917,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.21281214339589793\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 43,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.341623067855835,\\u003cbr\\u003e    0.3006134969325153\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 65,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00021621212244184927,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.2408858475427152\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 44,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2896411418914795,\\u003cbr\\u003e    0.46319018404907975\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 64,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00042478312403018025,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.16577774433066883\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 45,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3218549489974976,\\u003cbr\\u003e    0.43558282208588955\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 53,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00048239853924257056,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.20989102896299344\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 46,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2727833986282349,\\u003cbr\\u003e    0.4447852760736196\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 96,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.000748891525135518,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.3425772181690237\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 47,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3501240015029907,\\u003cbr\\u003e    0.3803680981595092\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 103,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00014448074921185518,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.26403893483523283\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 48,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2227370738983154,\\u003cbr\\u003e    0.4754601226993865\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 120,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0007840036283701464,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.13360350428840773\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 49,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3637171983718872,\\u003cbr\\u003e    0.3588957055214724\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 35,\\u003cbr\\u003e    \\\"learning_rate\\\": 7.273299717076955e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.1820285326961674\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 50,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.295709490776062,\\u003cbr\\u003e    0.46932515337423314\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 57,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0007567073829137522,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.1515200038915046\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 51,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3509070873260498,\\u003cbr\\u003e    0.401840490797546\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 48,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.098391653339911e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.21555292245983165\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 52,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3857232332229614,\\u003cbr\\u003e    0.2607361963190184\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 113,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00027160383219551756,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.26108908473928716\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 53,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.39391028881073,\\u003cbr\\u003e    0.2392638036809816\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 70,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00020962814592509894,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.48951108260583764\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 54,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3025257587432861,\\u003cbr\\u003e    0.4662576687116564\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 93,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0005878310606102539,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.26403893483523283\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 55,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3912590742111206,\\u003cbr\\u003e    0.26380368098159507\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 83,\\u003cbr\\u003e    \\\"learning_rate\\\": 6.303793388528524e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.29691219409890623\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 56,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3613134622573853,\\u003cbr\\u003e    0.31901840490797545\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 64,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00027160383219551756,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.33962331352990016\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 57,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3441736698150635,\\u003cbr\\u003e    0.41411042944785276\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 96,\\u003cbr\\u003e    \\\"learning_rate\\\": 8.878260027668817e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.16822162841669153\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 58,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3418045043945312,\\u003cbr\\u003e    0.40797546012269936\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 78,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0003432664598351407,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.34852254929365667\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 59,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2707329988479614,\\u003cbr\\u003e    0.43558282208588955\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 111,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0006690849303619035,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.43133601431322677\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 61,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.364633321762085,\\u003cbr\\u003e    0.31901840490797545\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 45,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0007567073829137522,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.1515200038915046\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 62,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.370531678199768,\\u003cbr\\u003e    0.2883435582822086\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 110,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00027160383219551756,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.25243856059031905\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 63,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.334957480430603,\\u003cbr\\u003e    0.3282208588957055\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 53,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0004311402013432208,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.21281214339589793\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 64,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.386417269706726,\\u003cbr\\u003e    0.32515337423312884\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 55,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00018072596452054285,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.13360350428840773\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 65,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3082722425460815,\\u003cbr\\u003e    0.44785276073619634\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 123,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00027160383219551756,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.30191010816390496\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 66,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2727231979370117,\\u003cbr\\u003e    0.46319018404907975\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 80,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0007942770390421613,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.22974979103055718\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 67,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3321714401245117,\\u003cbr\\u003e    0.3895705521472393\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 103,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00014448074921185518,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.27239521166440467\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 68,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3415597677230835,\\u003cbr\\u003e    0.43558282208588955\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 54,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00042478312403018025,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.16577774433066883\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 69,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.4055274724960327,\\u003cbr\\u003e    0.2392638036809816\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 71,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0002478409544913777,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.4655727645728217\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 70,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.317725658416748,\\u003cbr\\u003e    0.3834355828220859\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 40,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00012204610413258628,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.4119227032842442\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 71,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3774027824401855,\\u003cbr\\u003e    0.34662576687116564\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 97,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00029236126121637057,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.11064369645624104\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 72,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3616150617599487,\\u003cbr\\u003e    0.34355828220858897\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 96,\\u003cbr\\u003e    \\\"learning_rate\\\": 8.878260027668817e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.3847455570084011\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 73,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3664414882659912,\\u003cbr\\u003e    0.36503067484662577\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 79,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00024494956982896917,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.21281214339589793\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 74,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3894708156585693,\\u003cbr\\u003e    0.2361963190184049\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 64,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0002257401400822547,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.16577774433066883\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 75,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2578186988830566,\\u003cbr\\u003e    0.4662576687116564\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 112,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0009102727954844167,\\u003cbr\\u003e    \\\"num_layers\\\": 1,\\u003cbr\\u003e    \\\"dropout\\\": 0.21281214339589793\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 76,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3961007595062256,\\u003cbr\\u003e    0.3343558282208589\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 35,\\u003cbr\\u003e    \\\"learning_rate\\\": 7.273299717076955e-05,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.1820285326961674\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 77,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.264006495475769,\\u003cbr\\u003e    0.4570552147239264\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 110,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.000748891525135518,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.25243856059031905\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 78,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3332396745681763,\\u003cbr\\u003e    0.4754601226993865\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 96,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0003432664598351407,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.20989102896299344\\u003cbr\\u003e  }\\u003cbr\\u003e}\",\"{\\u003cbr\\u003e  \\\"number\\\": 79,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.3442562818527222,\\u003cbr\\u003e    0.3895705521472393\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 85,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.00013450089500356772,\\u003cbr\\u003e    \\\"num_layers\\\": 3,\\u003cbr\\u003e    \\\"dropout\\\": 0.19384966204494686\\u003cbr\\u003e  }\\u003cbr\\u003e}\"],\"x\":[1.350733995437622,1.2792413234710693,1.2947088479995728,1.3581626415252686,1.2928811311721802,1.3358443975448608,1.345978856086731,1.4478360414505005,1.4031413793563843,1.380328893661499,1.3054286241531372,1.3728636503219604,1.3301690816879272,1.366761326789856,1.396684169769287,1.3576345443725586,1.3497132062911987,1.3744920492172241,1.3838131427764893,1.3640621900558472,1.306557536125183,1.3560786247253418,1.2963348627090454,1.340586543083191,1.3649324178695679,1.394574761390686,1.3440070152282715,1.479681134223938,1.3552285432815552,1.3972316980361938,1.3819719552993774,1.3674043416976929,1.3804153203964233,1.3653942346572876,1.3862136602401733,1.3949803113937378,1.3041844367980957,1.365994930267334,1.376678228378296,1.3694357872009277,1.3581892251968384,1.430956244468689,1.344976544380188,1.341623067855835,1.2896411418914795,1.3218549489974976,1.2727833986282349,1.3501240015029907,1.2227370738983154,1.3637171983718872,1.295709490776062,1.3509070873260498,1.3857232332229614,1.39391028881073,1.3025257587432861,1.3912590742111206,1.3613134622573853,1.3441736698150635,1.3418045043945312,1.2707329988479614,1.364633321762085,1.370531678199768,1.334957480430603,1.386417269706726,1.3082722425460815,1.2727231979370117,1.3321714401245117,1.3415597677230835,1.4055274724960327,1.317725658416748,1.3774027824401855,1.3616150617599487,1.3664414882659912,1.3894708156585693,1.2578186988830566,1.3961007595062256,1.264006495475769,1.3332396745681763,1.3442562818527222],\"y\":[0.37116564417177916,0.48466257668711654,0.44171779141104295,0.30368098159509205,0.4539877300613497,0.3987730061349693,0.30368098159509205,0.15030674846625766,0.1687116564417178,0.2085889570552147,0.4171779141104294,0.29141104294478526,0.4325153374233129,0.3343558282208589,0.2607361963190184,0.3619631901840491,0.2822085889570552,0.3312883435582822,0.27607361963190186,0.36809815950920244,0.4447852760736196,0.42024539877300615,0.4171779141104294,0.40797546012269936,0.34662576687116564,0.26380368098159507,0.401840490797546,0.19325153374233128,0.48466257668711654,0.26380368098159507,0.24846625766871167,0.3773006134969325,0.29141104294478526,0.30368098159509205,0.25153374233128833,0.22392638036809817,0.36503067484662577,0.27300613496932513,0.3128834355828221,0.3159509202453988,0.4539877300613497,0.17484662576687116,0.401840490797546,0.3006134969325153,0.46319018404907975,0.43558282208588955,0.4447852760736196,0.3803680981595092,0.4754601226993865,0.3588957055214724,0.46932515337423314,0.401840490797546,0.2607361963190184,0.2392638036809816,0.4662576687116564,0.26380368098159507,0.31901840490797545,0.41411042944785276,0.40797546012269936,0.43558282208588955,0.31901840490797545,0.2883435582822086,0.3282208588957055,0.32515337423312884,0.44785276073619634,0.46319018404907975,0.3895705521472393,0.43558282208588955,0.2392638036809816,0.3834355828220859,0.34662576687116564,0.34355828220858897,0.36503067484662577,0.2361963190184049,0.4662576687116564,0.3343558282208589,0.4570552147239264,0.4754601226993865,0.3895705521472393],\"type\":\"scatter\"},{\"hovertemplate\":\"%{text}\\u003cextra\\u003eBest Trial\\u003c\\u002fextra\\u003e\",\"marker\":{\"color\":[60],\"colorbar\":{\"title\":{\"text\":\"Best Trial\"},\"x\":1.1,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(255,245,240)\"],[0.125,\"rgb(254,224,210)\"],[0.25,\"rgb(252,187,161)\"],[0.375,\"rgb(252,146,114)\"],[0.5,\"rgb(251,106,74)\"],[0.625,\"rgb(239,59,44)\"],[0.75,\"rgb(203,24,29)\"],[0.875,\"rgb(165,15,21)\"],[1.0,\"rgb(103,0,13)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5}},\"mode\":\"markers\",\"showlegend\":false,\"text\":[\"{\\u003cbr\\u003e  \\\"number\\\": 60,\\u003cbr\\u003e  \\\"values\\\": [\\u003cbr\\u003e    1.2200591564178467,\\u003cbr\\u003e    0.5061349693251533\\u003cbr\\u003e  ],\\u003cbr\\u003e  \\\"params\\\": {\\u003cbr\\u003e    \\\"hidden_size\\\": 110,\\u003cbr\\u003e    \\\"learning_rate\\\": 0.0008505924493379839,\\u003cbr\\u003e    \\\"num_layers\\\": 2,\\u003cbr\\u003e    \\\"dropout\\\": 0.11898358190583852\\u003cbr\\u003e  }\\u003cbr\\u003e}\"],\"x\":[1.2200591564178467],\"y\":[0.5061349693251533],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Pareto-front Plot\"},\"xaxis\":{\"title\":{\"text\":\"Objective 0\"}},\"yaxis\":{\"title\":{\"text\":\"Objective 1\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('12764f2c-e342-43c2-ad44-768ce0e75bc3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot shows the tradeoff of each trial between loss (objective 0) and accuracy (objective 1). The plot highlights the top left corner as the best trial, as it has the best tradeoff between loss and accuracy. Hovering over it, you can see that it was trial number 49, and it has a loss of 0.34 and accuracy of 0.89. This is much better than expected, leading me to believe there may be some overfitting.\n",
        "\n",
        "I am going to retrain it and run it against the testing data to truly see if it predicts that well, or if it is in fact overfit."
      ],
      "metadata": {
        "id": "34ekRpq2t3Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trial params: {'hidden_size': 110, 'learning_rate': 0.0008505924493379839, 'num_layers': 2, 'dropout': 0.11898358190583852}\n",
        "\n",
        "\n",
        "## Selected Hyperparameters\n",
        "hidden_size = 110\n",
        "learning_rate =  0.0008505924493379839\n",
        "num_layers = 2\n",
        "dropout = 0.11898358190583852\n",
        "\n",
        "## Create the model based on the function above\n",
        "model = create_gru_model(\n",
        "    input_size=21,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    output_size=4,\n",
        "    dropout_rate=dropout,\n",
        ")\n",
        "\n",
        "# Define Loss and Optimizer, adding a weight decay, an L2 Regularization, to help with overfitting\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "Qxt7W-ICwO33"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating PyTorch sensors for the training and testing\n",
        "X_train_tensor_sale = torch.tensor(X_train_sale, dtype=torch.float32)\n",
        "X_test_tensor_sale = torch.tensor(X_test_sale, dtype=torch.float32)\n",
        "\n",
        "# Convert one-hot encoded target to class indices\n",
        "y_train_sale_classes = np.argmax(y_train_sale, axis=1)\n",
        "y_train_tensor_sale = torch.tensor(y_train_sale_classes, dtype=torch.long)\n",
        "y_test_sale_classes = np.argmax(y_test_sale, axis=1)\n",
        "y_test_tensor_sale = torch.tensor(y_test_sale_classes, dtype=torch.long)\n",
        "\n",
        "# Create TensorDataset and DataLoader\n",
        "train_dataset_sale = TensorDataset(X_train_tensor_sale, y_train_tensor_sale)\n",
        "train_loader_sale = DataLoader(train_dataset_sale, batch_size= BATCHSIZE, shuffle=True)\n",
        "\n",
        "test_dataset_sale = TensorDataset(X_test_tensor_sale, y_test_tensor_sale)\n",
        "test_loader_sale = DataLoader(test_dataset_sale, batch_size=BATCHSIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "_Chiw8lXwjB_"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training model on selected epochs above\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_loader_sale:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        outputs = outputs[:, -1, :]\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "9G6aNZaKxCQ-"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluating the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor_sale)\n",
        "    outputs = outputs[:, -1, :]\n",
        "    loss = criterion(outputs, y_test_tensor_sale)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == y_test_tensor_sale).sum().item()\n",
        "    total = y_test_tensor_sale.size(0)\n",
        "    accuracy = correct / total\n",
        "\n",
        "print(f\"Test Loss: {loss.item()}, Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPIGdJANxPA8",
        "outputId": "dd5b52ca-3ab1-4308-8a04-a050802658eb"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.2198703289031982, Test Accuracy: 0.4024390243902439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This required a lot of playing around. Whether it be changing epochs, changing batch size, or changing the parameters, I tried many different combinations. Here were some of the trials I ran that had the best outputs.\n",
        "\n",
        "\n",
        "####**Trial 1**\n",
        "\n",
        "BATCHSIZE = 64\n",
        "EPOCHS = 15\n",
        "\n",
        "Trial params: {'hidden_size': 120, 'learning_rate': 0.009322631193715757, 'num_layers': 2, 'dropout': 0.17916460429601871}\n",
        "\n",
        "Test Loss: 1.4174426794052124, Test Accuracy: 0.5\n",
        "\n",
        "\n",
        "####**Trial 2**\n",
        "\n",
        "BATCHSIZE = 64\n",
        "EPOCHS = 12\n",
        "\n",
        "Trial params: {'hidden_size': 109, 'learning_rate': 0.006288788804388749, 'num_layers': 2, 'dropout': 0.14464301771388333}\n",
        "\n",
        "Test Loss: 1.1556916236877441, Test Accuracy: 0.5\n",
        "\n",
        "####**Trial 3**\n",
        "\n",
        "BATCHSIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "Trial params: {'hidden_size': 86, 'learning_rate': 0.009501936825399479, 'num_layers': 2, 'dropout': 0.13467693235734673}\n",
        "\n",
        "Test Loss: 1.1827853918075562, Test Accuracy: 0.5121951219512195\n",
        "\n",
        "####**Trial 4**\n",
        "\n",
        "BATCHSIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "Trial params: {'hidden_size': 59, 'learning_rate': 0.008258319100444264, 'num_layers': 1, 'dropout': 0.1136566167713085}\n",
        "\n",
        "Test Loss: 1.2344555854797363, Test Accuracy: 0.5\n",
        "\n",
        "\\\n",
        "###**Conclusion**\n",
        "\n",
        "We see that none of these trials are that great. I knew going in that the accuracy of this model was not going to be great. What I am looking for is the best balance between test loss and test accuracy. Trial 3 seems to be the best for me.\n",
        "\n",
        "\\\n",
        "So, my final model for Chris Sale is:\n",
        "\n",
        "Hidden Size: 86 \\\n",
        "Learning Rate: 0.009501936825399479 \\\n",
        "Number of Layers: 2 \\\n",
        "Dropout Rate: 0.13467693235734673\n",
        "\n",
        "\\\n",
        "I am going to fit this as my final model and then look at some of the common mistakes of this model."
      ],
      "metadata": {
        "id": "XXTc2WVy3dEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 86\n",
        "learning_rate =  0.009501936825399479\n",
        "num_layers = 2\n",
        "dropout = 0.13467693235734673\n",
        "BATCHSIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "## Fitting final model\n",
        "sale_model_final = create_gru_model(\n",
        "    input_size=21,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    output_size=4,\n",
        "    dropout_rate=dropout,\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "## Training\n",
        "for epoch in range(EPOCHS):\n",
        "    sale_model_final.train()\n",
        "    for batch_X, batch_y in train_loader_sale:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        outputs = outputs[:, -1, :]\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "## Making Predictions\n",
        "sale_model_final.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor_sale)\n",
        "    outputs = outputs[:, -1, :]\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "predicted_sale = predicted.cpu().numpy()\n",
        "true_labels_sale = y_test_tensor_sale.cpu().numpy()"
      ],
      "metadata": {
        "id": "xlShJr2A7_3H"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see some visuals as to where this model goes wrong."
      ],
      "metadata": {
        "id": "iZJMvKkV9GHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Confusion Matrix\n",
        "pitch_labels = [\"FF\", \"SL\", \"CH\", \"SI\"]\n",
        "\n",
        "true_pitch_labels_sale = [pitch_labels[label] for label in true_labels_sale]\n",
        "predicted_pitch_labels_sale = [pitch_labels[label] for label in predicted_sale]\n",
        "\n",
        "cm = confusion_matrix(true_pitch_labels_sale, predicted_pitch_labels_sale, labels=pitch_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=pitch_labels, yticklabels=pitch_labels)\n",
        "plt.xlabel('Predicted Pitches')\n",
        "plt.ylabel('True Pitches')\n",
        "plt.title('Chris Sale Pitching Confusion Matrix')\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "dFUBPiAM9JPG",
        "outputId": "ab61727d-0890-4939-96fb-8e7b6ef1605e"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the most common mistake made by the model is confusing Sinker and Slider. We see 11 pitches that were predicted to be sliders that were actually sinkers, and 9 that were predicted to be sinkers that were actually sliders. The second most common confusion by this model is Slider and Fastball. 11 pitches that were predicted slider were actually fastballs. What is quite interesting about this is that there is only 1 pitch that is the inverse.\n",
        "\n",
        "The pitch that is most common correctly predicted is sinker, as 23 predicted sinkers were actually sinkers. The second most common correctly predicted is slider, as 19 pitches were classified correctly in this category.\n",
        "\n",
        "Looking back at the pitch usage in the EDA, we see that Chris Sale uses his slider the most. So, it makes sense that most of the pitches were predicted to be sliders. However, he uses his four seam fastball the second most and his sinker the least, which is not reflected above. Based on pitch usage, I would think more would be predicted fastball, yet only 2 pitches were predicted so. On the other hand, sinkers were the least used pitch in 2024 for Chris Sale, yet it is the second most common prediction.\n",
        "\n",
        "Let's look at the first 5 sequences to see more."
      ],
      "metadata": {
        "id": "3DNhz2S_9zIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_5_sequences_sale = X_test_tensor_sale[:5]\n",
        "first_5_predictions_sale = predicted_sale[:5]\n",
        "first_5_true_labels_sale = true_labels_sale[:5]\n",
        "\n",
        "# Convert numerical labels to pitch names\n",
        "predicted_pitches_sale = [pitch_labels[label] for label in first_5_predictions_sale]\n",
        "true_pitches_sale = [pitch_labels[label] for label in first_5_true_labels_sale]\n",
        "\n",
        "# Extract the first three pitches from each sequence (assuming 21 features)\n",
        "first_3_pitches = []\n",
        "for sequence in first_5_sequences_sale:\n",
        "    sequence_pitches = []\n",
        "    for i in range(3):\n",
        "        pitch_number = int(sequence[i, 0].item())\n",
        "        sequence_pitches.append(pitch_labels[pitch_number])\n",
        "    first_3_pitches.append(sequence_pitches)\n",
        "\n",
        "# Create the DataFrame\n",
        "data_sale = {\n",
        "    \"Sequence Number\": range(5),\n",
        "    \"Pitch 1\": [pitches[0] for pitches in first_3_pitches],\n",
        "    \"Pitch 2\": [pitches[1] for pitches in first_3_pitches],\n",
        "    \"Pitch 3\": [pitches[2] for pitches in first_3_pitches],\n",
        "    \"Predicted Pitch 4\": predicted_pitches_sale,\n",
        "    \"Actual Pitch 4\": true_pitches_sale,\n",
        "}\n",
        "\n",
        "df_sale = pd.DataFrame(data_sale)\n",
        "print(\"\\033[1m\\033[94mChris Sale's First 5 Pitch Sequences in 2024.\\033[0m\")\n",
        "df_sale\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "b7QTfoZAAGn_",
        "outputId": "a20a50fa-1162-412a-9c64-90cdf04583a1"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[94mChris Sale's First 5 Pitch Sequences in 2024.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sequence Number Pitch 1 Pitch 2 Pitch 3 Predicted Pitch 4 Actual Pitch 4\n",
              "0                0      FF      FF      SI                SL             SL\n",
              "1                1      SI      FF      FF                SL             SL\n",
              "2                2      SL      FF      SI                SI             SI\n",
              "3                3      FF      SI      SI                SL             SI\n",
              "4                4      FF      FF      SL                SL             SI"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe3ccb6a-70e7-4791-93c5-3b93a2e7d309\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence Number</th>\n",
              "      <th>Pitch 1</th>\n",
              "      <th>Pitch 2</th>\n",
              "      <th>Pitch 3</th>\n",
              "      <th>Predicted Pitch 4</th>\n",
              "      <th>Actual Pitch 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>FF</td>\n",
              "      <td>FF</td>\n",
              "      <td>SI</td>\n",
              "      <td>SL</td>\n",
              "      <td>SL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>SI</td>\n",
              "      <td>FF</td>\n",
              "      <td>FF</td>\n",
              "      <td>SL</td>\n",
              "      <td>SL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>SL</td>\n",
              "      <td>FF</td>\n",
              "      <td>SI</td>\n",
              "      <td>SI</td>\n",
              "      <td>SI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>FF</td>\n",
              "      <td>SI</td>\n",
              "      <td>SI</td>\n",
              "      <td>SL</td>\n",
              "      <td>SI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>FF</td>\n",
              "      <td>FF</td>\n",
              "      <td>SL</td>\n",
              "      <td>SL</td>\n",
              "      <td>SI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe3ccb6a-70e7-4791-93c5-3b93a2e7d309')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe3ccb6a-70e7-4791-93c5-3b93a2e7d309 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe3ccb6a-70e7-4791-93c5-3b93a2e7d309');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0926dea-019a-45c2-bcd6-dab848db6fb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0926dea-019a-45c2-bcd6-dab848db6fb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0926dea-019a-45c2-bcd6-dab848db6fb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_de0dee31-1adf-44f4-abcf-a4b24755bff4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sale')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_de0dee31-1adf-44f4-abcf-a4b24755bff4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sale');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sale",
              "summary": "{\n  \"name\": \"df_sale\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Sequence Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pitch 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"FF\",\n          \"SI\",\n          \"SL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pitch 2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SI\",\n          \"FF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pitch 3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SI\",\n          \"FF\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Pitch 4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SI\",\n          \"SL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Pitch 4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SI\",\n          \"SL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is cool just to look at the first 5 sequences to see if they were correct and what pitches came before. The first 3 sequences were predicted correctly. However, the final 2 were predicted to be sliders that were actually sinkers. Based on Chris Sale's Pitch Usage, this makes sense.\n",
        "\n",
        "Before we can jump to any mega-final conclusions, it is time to model Tarik Skubal!"
      ],
      "metadata": {
        "id": "TTDlXjiRCV1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tarik Skubal\n",
        "\n",
        "I am going to follow the exact same methods as I did for Chris Sale."
      ],
      "metadata": {
        "id": "VaQHYRR6DVQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Tarik Skubal Sequences\n",
        "def create_sequences_skubal(data, features, sequence_length=3):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    for seq_id, group in data.groupby('seq_id'):\n",
        "        pitch_features = group[features].values\n",
        "        pitch_types = group[['pitch_type_CH', 'pitch_type_FF', 'pitch_type_KC','pitch_type_SI', 'pitch_type_SL']].values\n",
        "\n",
        "        if len(pitch_features) >= sequence_length + 1:\n",
        "            for i in range(len(pitch_features) - sequence_length):\n",
        "                sequences.append(pitch_features[i:i + sequence_length])\n",
        "                targets.append(pitch_types[i + sequence_length])\n",
        "\n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "\n",
        "## Explanatory pitch features\n",
        "features = ['release_speed', 'release_pos_x', 'release_pos_y', 'release_pos_z',\n",
        "            'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z', 'plate_x', 'plate_z',\n",
        "            'sz_top', 'sz_bot', 'balls', 'strikes', 'outs_when_up', 'inning',\n",
        "            'inning_topbot_Bot', 'inning_topbot_Top', 'stand_L', 'stand_R', 'p_throws_L']\n",
        "\n",
        "X, y = create_sequences_skubal(skubal, features)\n",
        "\n",
        "def train_test_split_sequences_skubal(data, features, test_size=0.2):\n",
        "\n",
        "    unique_seq_ids = data['seq_id'].unique()\n",
        "    train_ids, test_ids = train_test_split(unique_seq_ids, test_size=test_size, random_state=42)\n",
        "\n",
        "    train_df = data[data['seq_id'].isin(train_ids)]\n",
        "    test_df = data[data['seq_id'].isin(test_ids)]\n",
        "\n",
        "    X_train, y_train = create_sequences_skubal(train_df, features)\n",
        "    X_test, y_test = create_sequences_skubal(test_df, features)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "## Creating actual splits\n",
        "X_train_skubal, y_train_skubal, X_test_skubal, y_test_skubal = train_test_split_sequences_skubal(skubal, features)"
      ],
      "metadata": {
        "id": "QFa5UfSADfKZ"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the sequences, it's time for hyperparameter tuning."
      ],
      "metadata": {
        "id": "wLHMXdnhEfH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCHSIZE = 64\n",
        "EPOCHS = 10\n",
        "DIR = os.getcwd()\n",
        "\n",
        "## Can use the same create_gru_model() and Lambda Class as above, since it does not change for each pitcher.\n",
        "\n",
        "## For Hyperparameter Tuning\n",
        "def objective_skubal(trial):\n",
        "\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 128)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 3])\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "\n",
        "    ## Create GRU model using above function\n",
        "    model = create_gru_model(input_size=21, hidden_size=hidden_size, num_layers=num_layers, output_size=5, dropout_rate= dropout)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    ## Converting data to PyTorch tensors\n",
        "    X_train_tensor = torch.tensor(X_train_skubal, dtype=torch.float32)\n",
        "\n",
        "    # Convert one-hot encoded target to class indices\n",
        "    y_train_skubal_classes = np.argmax(y_train_skubal, axis=1)\n",
        "    y_train_tensor = torch.tensor(y_train_skubal_classes, dtype=torch.long)\n",
        "\n",
        "    # Training over epochs\n",
        "    for epoch in range(EPOCHS):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train_tensor)\n",
        "        outputs = outputs[:, -1, :]\n",
        "        loss = criterion(outputs, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_train_tensor)\n",
        "        outputs = outputs[:, -1, :]\n",
        "        loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct = (predicted == y_train_tensor).sum().item()\n",
        "        total = y_train_tensor.size(0)\n",
        "        accuracy = correct / total\n",
        "\n",
        "    return loss.item(), accuracy  # Return both loss and accuracy\n",
        "\n",
        "# Create and run the Optuna study\n",
        "study_skubal = optuna.create_study(directions=[\"minimize\", \"maximize\"])\n",
        "study_skubal.optimize(objective_skubal, n_trials=80, n_jobs=1)\n",
        "\n",
        "\n",
        "# Get the best trial and hyperparameters\n",
        "best_trials_skubal = study_skubal.best_trials\n",
        "\n",
        "# Print the best trials\n",
        "for trial in best_trials_skubal:\n",
        "    print(\"Trial params:\", trial.params)\n",
        "    print(\"Trial Accuracy:\", trial.values[1])\n",
        "    print(\"Trial Loss:\", trial.values[0])\n",
        "\n",
        "study_filename_skubal = \"optuna_study_skubal.pkl\"\n",
        "joblib.dump(study_skubal, study_filename_skubal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW3T5SqMEeCk",
        "outputId": "9f700e71-b48f-497d-e747-d2620d864e3a"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-25 20:58:16,072] A new study created in memory with name: no-name-941f97a1-b40f-4aeb-953e-b42c7fbd8016\n",
            "[I 2025-03-25 20:58:16,384] Trial 0 finished with values: [1.3910924196243286, 0.39097744360902253] and parameters: {'hidden_size': 73, 'learning_rate': 0.0013451550916233597, 'num_layers': 3, 'dropout': 0.1357425549460586}.\n",
            "[I 2025-03-25 20:58:16,531] Trial 1 finished with values: [1.4650449752807617, 0.3383458646616541] and parameters: {'hidden_size': 95, 'learning_rate': 0.0017488372355886743, 'num_layers': 1, 'dropout': 0.49543945559076263}.\n",
            "[I 2025-03-25 20:58:16,789] Trial 2 finished with values: [1.2192535400390625, 0.48872180451127817] and parameters: {'hidden_size': 89, 'learning_rate': 0.009512591120465786, 'num_layers': 2, 'dropout': 0.40698195049827934}.\n",
            "[I 2025-03-25 20:58:17,068] Trial 3 finished with values: [1.5821863412857056, 0.2781954887218045] and parameters: {'hidden_size': 53, 'learning_rate': 0.0002617374992355524, 'num_layers': 2, 'dropout': 0.36103857257329475}.\n",
            "[I 2025-03-25 20:58:17,486] Trial 4 finished with values: [1.5211848020553589, 0.38345864661654133] and parameters: {'hidden_size': 61, 'learning_rate': 0.0007082808599462571, 'num_layers': 2, 'dropout': 0.25273785357717315}.\n",
            "[I 2025-03-25 20:58:17,740] Trial 5 finished with values: [0.974607527256012, 0.6015037593984962] and parameters: {'hidden_size': 102, 'learning_rate': 0.009416482994198196, 'num_layers': 2, 'dropout': 0.12116636307630856}.\n",
            "[I 2025-03-25 20:58:17,845] Trial 6 finished with values: [1.5853190422058105, 0.2781954887218045] and parameters: {'hidden_size': 97, 'learning_rate': 0.0002662845493836426, 'num_layers': 1, 'dropout': 0.30719778394770697}.\n",
            "[I 2025-03-25 20:58:18,140] Trial 7 finished with values: [1.3412388563156128, 0.38345864661654133] and parameters: {'hidden_size': 97, 'learning_rate': 0.0017461796681801146, 'num_layers': 3, 'dropout': 0.14568484651138622}.\n",
            "[I 2025-03-25 20:58:18,213] Trial 8 finished with values: [1.6238445043563843, 0.2706766917293233] and parameters: {'hidden_size': 35, 'learning_rate': 0.0005210882483661722, 'num_layers': 1, 'dropout': 0.24883923923957485}.\n",
            "[I 2025-03-25 20:58:18,731] Trial 9 finished with values: [1.1403785943984985, 0.49624060150375937] and parameters: {'hidden_size': 105, 'learning_rate': 0.008270178495924907, 'num_layers': 3, 'dropout': 0.24132657456158882}.\n",
            "[I 2025-03-25 20:58:18,823] Trial 10 finished with values: [1.410400152206421, 0.42857142857142855] and parameters: {'hidden_size': 98, 'learning_rate': 0.0015235108445550815, 'num_layers': 1, 'dropout': 0.19662259273486193}.\n",
            "[I 2025-03-25 20:58:19,070] Trial 11 finished with values: [1.5496468544006348, 0.39849624060150374] and parameters: {'hidden_size': 119, 'learning_rate': 0.0003516525299080466, 'num_layers': 3, 'dropout': 0.28142794668057763}.\n",
            "[I 2025-03-25 20:58:19,149] Trial 12 finished with values: [1.6025944948196411, 0.3007518796992481] and parameters: {'hidden_size': 77, 'learning_rate': 0.000547482593707484, 'num_layers': 1, 'dropout': 0.3156161458259297}.\n",
            "[I 2025-03-25 20:58:19,244] Trial 13 finished with values: [1.5255833864212036, 0.3082706766917293] and parameters: {'hidden_size': 71, 'learning_rate': 0.0009328729196176443, 'num_layers': 1, 'dropout': 0.2279647182188335}.\n",
            "[I 2025-03-25 20:58:19,343] Trial 14 finished with values: [1.6578998565673828, 0.18045112781954886] and parameters: {'hidden_size': 97, 'learning_rate': 0.0001150686643521377, 'num_layers': 1, 'dropout': 0.45430865415124455}.\n",
            "[I 2025-03-25 20:58:19,449] Trial 15 finished with values: [1.5875519514083862, 0.2631578947368421] and parameters: {'hidden_size': 55, 'learning_rate': 0.0004028601371005961, 'num_layers': 2, 'dropout': 0.33815661076352066}.\n",
            "[I 2025-03-25 20:58:19,779] Trial 16 finished with values: [1.4199070930480957, 0.38345864661654133] and parameters: {'hidden_size': 120, 'learning_rate': 0.0011410096304488326, 'num_layers': 3, 'dropout': 0.38875132467838636}.\n",
            "[I 2025-03-25 20:58:19,944] Trial 17 finished with values: [1.562400460243225, 0.3007518796992481] and parameters: {'hidden_size': 83, 'learning_rate': 0.0002989440163077506, 'num_layers': 2, 'dropout': 0.44480485478362164}.\n",
            "[I 2025-03-25 20:58:20,055] Trial 18 finished with values: [1.6629756689071655, 0.15789473684210525] and parameters: {'hidden_size': 93, 'learning_rate': 0.0001351141402960099, 'num_layers': 1, 'dropout': 0.4263527055577355}.\n",
            "[I 2025-03-25 20:58:20,153] Trial 19 finished with values: [1.6204290390014648, 0.18796992481203006] and parameters: {'hidden_size': 93, 'learning_rate': 0.00013172985751211698, 'num_layers': 1, 'dropout': 0.14223307739869764}.\n",
            "[I 2025-03-25 20:58:20,342] Trial 20 finished with values: [1.6032687425613403, 0.3007518796992481] and parameters: {'hidden_size': 59, 'learning_rate': 0.00012898226638393372, 'num_layers': 3, 'dropout': 0.3956386762910632}.\n",
            "[I 2025-03-25 20:58:20,435] Trial 21 finished with values: [1.3628698587417603, 0.39097744360902253] and parameters: {'hidden_size': 63, 'learning_rate': 0.00442650421768677, 'num_layers': 1, 'dropout': 0.3619067994620645}.\n",
            "[I 2025-03-25 20:58:20,647] Trial 22 finished with values: [1.5964093208312988, 0.3082706766917293] and parameters: {'hidden_size': 109, 'learning_rate': 0.0001555488140802761, 'num_layers': 2, 'dropout': 0.19091189286465626}.\n",
            "[I 2025-03-25 20:58:20,777] Trial 23 finished with values: [1.344576120376587, 0.45112781954887216] and parameters: {'hidden_size': 51, 'learning_rate': 0.0055001022000817495, 'num_layers': 2, 'dropout': 0.4631206774450757}.\n",
            "[I 2025-03-25 20:58:20,833] Trial 24 finished with values: [1.653631567955017, 0.15789473684210525] and parameters: {'hidden_size': 37, 'learning_rate': 0.00016891212824375607, 'num_layers': 1, 'dropout': 0.34778115142248556}.\n",
            "[I 2025-03-25 20:58:20,894] Trial 25 finished with values: [1.2169629335403442, 0.5112781954887218] and parameters: {'hidden_size': 32, 'learning_rate': 0.008917246048151499, 'num_layers': 3, 'dropout': 0.1549163089512875}.\n",
            "[I 2025-03-25 20:58:20,985] Trial 26 finished with values: [1.3763924837112427, 0.37593984962406013] and parameters: {'hidden_size': 35, 'learning_rate': 0.008288913562084152, 'num_layers': 3, 'dropout': 0.2970710344692172}.\n",
            "[I 2025-03-25 20:58:21,127] Trial 27 finished with values: [1.4178080558776855, 0.42105263157894735] and parameters: {'hidden_size': 61, 'learning_rate': 0.006368208605081049, 'num_layers': 3, 'dropout': 0.4715321156883989}.\n",
            "[I 2025-03-25 20:58:21,321] Trial 28 finished with values: [1.4954586029052734, 0.3458646616541353] and parameters: {'hidden_size': 104, 'learning_rate': 0.0007741499440777766, 'num_layers': 3, 'dropout': 0.22290468103784136}.\n",
            "[I 2025-03-25 20:58:21,376] Trial 29 finished with values: [1.57115638256073, 0.3157894736842105] and parameters: {'hidden_size': 65, 'learning_rate': 0.0004620544011528651, 'num_layers': 1, 'dropout': 0.48490411378290577}.\n",
            "[I 2025-03-25 20:58:21,460] Trial 30 finished with values: [1.4034419059753418, 0.45864661654135336] and parameters: {'hidden_size': 112, 'learning_rate': 0.0019140971999854683, 'num_layers': 1, 'dropout': 0.2720643390202624}.\n",
            "[I 2025-03-25 20:58:21,556] Trial 31 finished with values: [1.5656018257141113, 0.21804511278195488] and parameters: {'hidden_size': 41, 'learning_rate': 0.0003754675542559689, 'num_layers': 3, 'dropout': 0.29104416322205917}.\n",
            "[I 2025-03-25 20:58:21,765] Trial 32 finished with values: [1.3477298021316528, 0.39097744360902253] and parameters: {'hidden_size': 98, 'learning_rate': 0.0027358778041503785, 'num_layers': 3, 'dropout': 0.3043292268678535}.\n",
            "[I 2025-03-25 20:58:21,855] Trial 33 finished with values: [1.4835878610610962, 0.39849624060150374] and parameters: {'hidden_size': 39, 'learning_rate': 0.0016516659936083472, 'num_layers': 2, 'dropout': 0.24335957884306336}.\n",
            "[I 2025-03-25 20:58:21,936] Trial 34 finished with values: [1.6213487386703491, 0.14285714285714285] and parameters: {'hidden_size': 34, 'learning_rate': 0.00010263840655012435, 'num_layers': 3, 'dropout': 0.1189517390695821}.\n",
            "[I 2025-03-25 20:58:21,996] Trial 35 finished with values: [1.5881338119506836, 0.2781954887218045] and parameters: {'hidden_size': 88, 'learning_rate': 0.00016672052910044976, 'num_layers': 1, 'dropout': 0.3181734859286041}.\n",
            "[I 2025-03-25 20:58:22,056] Trial 36 finished with values: [1.6122541427612305, 0.12781954887218044] and parameters: {'hidden_size': 90, 'learning_rate': 0.00020219107994185116, 'num_layers': 1, 'dropout': 0.12464302284995919}.\n",
            "[I 2025-03-25 20:58:22,151] Trial 37 finished with values: [1.3408218622207642, 0.38345864661654133] and parameters: {'hidden_size': 59, 'learning_rate': 0.008953533790461963, 'num_layers': 2, 'dropout': 0.430277641916217}.\n",
            "[I 2025-03-25 20:58:22,237] Trial 38 finished with values: [1.5999746322631836, 0.2706766917293233] and parameters: {'hidden_size': 89, 'learning_rate': 0.00011457156570837301, 'num_layers': 1, 'dropout': 0.11978349023515321}.\n",
            "[I 2025-03-25 20:58:22,321] Trial 39 finished with values: [1.3935270309448242, 0.42105263157894735] and parameters: {'hidden_size': 65, 'learning_rate': 0.0022426167003833275, 'num_layers': 2, 'dropout': 0.41768452826939684}.\n",
            "[I 2025-03-25 20:58:22,556] Trial 40 finished with values: [1.5774623155593872, 0.2857142857142857] and parameters: {'hidden_size': 115, 'learning_rate': 0.00012037148701680784, 'num_layers': 3, 'dropout': 0.21244849479174333}.\n",
            "[I 2025-03-25 20:58:22,677] Trial 41 finished with values: [1.43263578414917, 0.39849624060150374] and parameters: {'hidden_size': 90, 'learning_rate': 0.005496400521113245, 'num_layers': 2, 'dropout': 0.48341277376756386}.\n",
            "[I 2025-03-25 20:58:22,776] Trial 42 finished with values: [1.492870807647705, 0.3233082706766917] and parameters: {'hidden_size': 46, 'learning_rate': 0.0009897293398567297, 'num_layers': 3, 'dropout': 0.3188493962555613}.\n",
            "[I 2025-03-25 20:58:22,955] Trial 43 finished with values: [1.2501469850540161, 0.45864661654135336] and parameters: {'hidden_size': 99, 'learning_rate': 0.0037807518149721915, 'num_layers': 3, 'dropout': 0.12530222828069953}.\n",
            "[I 2025-03-25 20:58:23,019] Trial 44 finished with values: [1.5450959205627441, 0.42857142857142855] and parameters: {'hidden_size': 99, 'learning_rate': 0.0003518543698202288, 'num_layers': 1, 'dropout': 0.12684448589078479}.\n",
            "[I 2025-03-25 20:58:23,120] Trial 45 finished with values: [1.1093511581420898, 0.5338345864661654] and parameters: {'hidden_size': 68, 'learning_rate': 0.009077964724425675, 'num_layers': 2, 'dropout': 0.17795050503635884}.\n",
            "[I 2025-03-25 20:58:23,206] Trial 46 finished with values: [1.2574228048324585, 0.45864661654135336] and parameters: {'hidden_size': 54, 'learning_rate': 0.005085099892403306, 'num_layers': 2, 'dropout': 0.24458510130545563}.\n",
            "[I 2025-03-25 20:58:23,362] Trial 47 finished with values: [1.530997633934021, 0.39849624060150374] and parameters: {'hidden_size': 127, 'learning_rate': 0.00047838903076618476, 'num_layers': 2, 'dropout': 0.37708996326903044}.\n",
            "[I 2025-03-25 20:58:23,410] Trial 48 finished with values: [1.6039249897003174, 0.2706766917293233] and parameters: {'hidden_size': 83, 'learning_rate': 0.00015881371744558818, 'num_layers': 1, 'dropout': 0.41732350645724725}.\n",
            "[I 2025-03-25 20:58:23,499] Trial 49 finished with values: [1.5663537979125977, 0.2857142857142857] and parameters: {'hidden_size': 76, 'learning_rate': 0.00027255536360346706, 'num_layers': 2, 'dropout': 0.4348660440765222}.\n",
            "[I 2025-03-25 20:58:23,613] Trial 50 finished with values: [1.3114396333694458, 0.44360902255639095] and parameters: {'hidden_size': 59, 'learning_rate': 0.008309491174209637, 'num_layers': 3, 'dropout': 0.38875132467838636}.\n",
            "[I 2025-03-25 20:58:23,714] Trial 51 finished with values: [1.5121575593948364, 0.3684210526315789] and parameters: {'hidden_size': 61, 'learning_rate': 0.0007082808599462571, 'num_layers': 2, 'dropout': 0.12116636307630856}.\n",
            "[I 2025-03-25 20:58:23,809] Trial 52 finished with values: [1.5975737571716309, 0.2631578947368421] and parameters: {'hidden_size': 63, 'learning_rate': 0.00011893231403746397, 'num_layers': 2, 'dropout': 0.3619067994620645}.\n",
            "[I 2025-03-25 20:58:23,888] Trial 53 finished with values: [1.6221250295639038, 0.15789473684210525] and parameters: {'hidden_size': 93, 'learning_rate': 0.00013172985751211698, 'num_layers': 1, 'dropout': 0.14223307739869764}.\n",
            "[I 2025-03-25 20:58:24,072] Trial 54 finished with values: [1.349239706993103, 0.42105263157894735] and parameters: {'hidden_size': 99, 'learning_rate': 0.0018145838114259879, 'num_layers': 3, 'dropout': 0.21976648454443148}.\n",
            "[I 2025-03-25 20:58:24,184] Trial 55 finished with values: [1.564049243927002, 0.3684210526315789] and parameters: {'hidden_size': 65, 'learning_rate': 0.0004620544011528651, 'num_layers': 3, 'dropout': 0.41819389979204813}.\n",
            "[I 2025-03-25 20:58:24,282] Trial 56 finished with values: [1.4152615070343018, 0.38345864661654133] and parameters: {'hidden_size': 96, 'learning_rate': 0.0016516659936083472, 'num_layers': 2, 'dropout': 0.430277641916217}.\n",
            "[I 2025-03-25 20:58:24,442] Trial 57 finished with values: [1.4145352840423584, 0.3684210526315789] and parameters: {'hidden_size': 97, 'learning_rate': 0.0009897293398567297, 'num_layers': 3, 'dropout': 0.30719778394770697}.\n",
            "[I 2025-03-25 20:58:24,480] Trial 58 finished with values: [1.436496376991272, 0.45112781954887216] and parameters: {'hidden_size': 65, 'learning_rate': 0.0019140971999854683, 'num_layers': 1, 'dropout': 0.15438167033679817}.\n",
            "[I 2025-03-25 20:58:24,766] Trial 59 finished with values: [1.5340030193328857, 0.38345864661654133] and parameters: {'hidden_size': 119, 'learning_rate': 0.0003516525299080466, 'num_layers': 3, 'dropout': 0.13030296939147284}.\n",
            "[I 2025-03-25 20:58:24,856] Trial 60 finished with values: [1.4295005798339844, 0.46616541353383456] and parameters: {'hidden_size': 98, 'learning_rate': 0.0015235108445550815, 'num_layers': 1, 'dropout': 0.19662259273486193}.\n",
            "[I 2025-03-25 20:58:25,098] Trial 61 finished with values: [1.600306510925293, 0.24060150375939848] and parameters: {'hidden_size': 109, 'learning_rate': 0.0001555488140802761, 'num_layers': 2, 'dropout': 0.19091189286465626}.\n",
            "[I 2025-03-25 20:58:25,366] Trial 62 finished with values: [1.0958771705627441, 0.49624060150375937] and parameters: {'hidden_size': 82, 'learning_rate': 0.008917246048151499, 'num_layers': 3, 'dropout': 0.1549163089512875}.\n",
            "[I 2025-03-25 20:58:25,497] Trial 63 finished with values: [1.5728294849395752, 0.2932330827067669] and parameters: {'hidden_size': 35, 'learning_rate': 0.00019423461021377464, 'num_layers': 3, 'dropout': 0.48341277376756386}.\n",
            "[I 2025-03-25 20:58:25,596] Trial 64 finished with values: [1.548074722290039, 0.3458646616541353] and parameters: {'hidden_size': 77, 'learning_rate': 0.000547482593707484, 'num_layers': 1, 'dropout': 0.3156161458259297}.\n",
            "[I 2025-03-25 20:58:26,035] Trial 65 finished with values: [1.4665087461471558, 0.38345864661654133] and parameters: {'hidden_size': 78, 'learning_rate': 0.0009389347591794528, 'num_layers': 3, 'dropout': 0.22290468103784136}.\n",
            "[I 2025-03-25 20:58:26,286] Trial 66 finished with values: [1.574596643447876, 0.3684210526315789] and parameters: {'hidden_size': 95, 'learning_rate': 0.0003401757297008659, 'num_layers': 2, 'dropout': 0.49543945559076263}.\n",
            "[I 2025-03-25 20:58:26,423] Trial 67 finished with values: [1.2616512775421143, 0.39849624060150374] and parameters: {'hidden_size': 99, 'learning_rate': 0.005127103489935248, 'num_layers': 1, 'dropout': 0.20370542079127057}.\n",
            "[I 2025-03-25 20:58:26,641] Trial 68 finished with values: [1.6278403997421265, 0.18045112781954886] and parameters: {'hidden_size': 90, 'learning_rate': 0.0002989440163077506, 'num_layers': 2, 'dropout': 0.44480485478362164}.\n",
            "[I 2025-03-25 20:58:27,141] Trial 69 finished with values: [0.9896976947784424, 0.6090225563909775] and parameters: {'hidden_size': 89, 'learning_rate': 0.009512591120465786, 'num_layers': 3, 'dropout': 0.1549163089512875}.\n",
            "[I 2025-03-25 20:58:27,334] Trial 70 finished with values: [1.3750137090682983, 0.40601503759398494] and parameters: {'hidden_size': 98, 'learning_rate': 0.0015235108445550815, 'num_layers': 2, 'dropout': 0.12116636307630856}.\n",
            "[I 2025-03-25 20:58:27,500] Trial 71 finished with values: [1.384156346321106, 0.42857142857142855] and parameters: {'hidden_size': 61, 'learning_rate': 0.006368208605081049, 'num_layers': 3, 'dropout': 0.4715321156883989}.\n",
            "[I 2025-03-25 20:58:27,638] Trial 72 finished with values: [1.308577299118042, 0.46616541353383456] and parameters: {'hidden_size': 68, 'learning_rate': 0.009077964724425675, 'num_layers': 2, 'dropout': 0.35798041336483155}.\n",
            "[I 2025-03-25 20:58:27,777] Trial 73 finished with values: [1.5671806335449219, 0.3533834586466165] and parameters: {'hidden_size': 61, 'learning_rate': 0.0004525169562758209, 'num_layers': 2, 'dropout': 0.28142794668057763}.\n",
            "[I 2025-03-25 20:58:27,871] Trial 74 finished with values: [1.4009019136428833, 0.43609022556390975] and parameters: {'hidden_size': 112, 'learning_rate': 0.0019140971999854683, 'num_layers': 1, 'dropout': 0.2720643390202624}.\n",
            "[I 2025-03-25 20:58:27,981] Trial 75 finished with values: [1.3221529722213745, 0.42105263157894735] and parameters: {'hidden_size': 38, 'learning_rate': 0.009416482994198196, 'num_layers': 2, 'dropout': 0.30719778394770697}.\n",
            "[I 2025-03-25 20:58:28,166] Trial 76 finished with values: [1.6191664934158325, 0.3082706766917293] and parameters: {'hidden_size': 61, 'learning_rate': 0.000547482593707484, 'num_layers': 1, 'dropout': 0.4715321156883989}.\n",
            "[I 2025-03-25 20:58:28,325] Trial 77 finished with values: [1.6162317991256714, 0.17293233082706766] and parameters: {'hidden_size': 51, 'learning_rate': 0.00015210962988555167, 'num_layers': 2, 'dropout': 0.20771825458643545}.\n",
            "[I 2025-03-25 20:58:28,594] Trial 78 finished with values: [1.3222923278808594, 0.5338345864661654] and parameters: {'hidden_size': 95, 'learning_rate': 0.008917246048151499, 'num_layers': 3, 'dropout': 0.49543945559076263}.\n",
            "[I 2025-03-25 20:58:28,774] Trial 79 finished with values: [1.3880019187927246, 0.3609022556390977] and parameters: {'hidden_size': 90, 'learning_rate': 0.006368208605081049, 'num_layers': 2, 'dropout': 0.4945152313243183}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial params: {'hidden_size': 102, 'learning_rate': 0.009416482994198196, 'num_layers': 2, 'dropout': 0.12116636307630856}\n",
            "Trial Accuracy: 0.6015037593984962\n",
            "Trial Loss: 0.974607527256012\n",
            "Trial params: {'hidden_size': 89, 'learning_rate': 0.009512591120465786, 'num_layers': 3, 'dropout': 0.1549163089512875}\n",
            "Trial Accuracy: 0.6090225563909775\n",
            "Trial Loss: 0.9896976947784424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['optuna_study_skubal.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    }
  ]
}